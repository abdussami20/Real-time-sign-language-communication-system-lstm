Real-Time Sign Language Communication System

A real-time sign language recognition system built using **Computer Vision** and **Deep Learning**.  
This project enables seamless communication between deaf/mute individuals and others by converting hand gestures into textual and/or audio outputs.

---
<img width="1920" height="1080" alt="Your paragraph text (1)" src="https://github.com/user-attachments/assets/4a3deed2-203f-45b1-9156-9d0ec12065c5" />
![Interface](https://github.com/user-attachments/assets/693aa6a6-2108-440f-a9ac-0b8e2b4fb992)



Features

- Real-time gesture recognition using video feed  
- LSTM-based sequence classification for sign prediction  
- Integration with Flask for a live web interface  
- Designed for accessibility and assistive technology applications  
- Modular and scalable for further AI improvements  

---

Technologies Used

- **Python** – core programming  
- **TensorFlow** – model training & evaluation  
- **OpenCV** – video capture & image processing  
- **Flask** – web application interface  
- **NumPy / Pandas** – data manipulation  
- **Frontend** – React for UI components  

---

Installation

1. Clone the repository:

```bash
git clone https://github.com/yourusername/Real-time-sign-language-communication-system.git
cd fyp_webapp
