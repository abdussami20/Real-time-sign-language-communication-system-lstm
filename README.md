Real-Time Sign Language Communication System

A real-time sign language recognition system built using **Computer Vision** and **Deep Learning**.  
This project enables seamless communication between deaf/mute individuals and others by converting hand gestures into textual and/or audio outputs.

---
<img width="1920" height="1080" alt="Your paragraph text (1)" src="https://github.com/user-attachments/assets/4a3deed2-203f-45b1-9156-9d0ec12065c5" />
![WhatsApp Image 2026-02-06 at 1 07 03 AM](https://github.com/user-attachments/assets/271b228a-e74b-480b-b258-6c4a25d40251)


Features

- Real-time gesture recognition using video feed  
- LSTM-based sequence classification for sign prediction  
- Integration with Flask for a live web interface  
- Designed for accessibility and assistive technology applications  
- Modular and scalable for further AI improvements  

---

Technologies Used

- **Python** – core programming  
- **TensorFlow** – model training & evaluation  
- **OpenCV** – video capture & image processing  
- **Flask** – web application interface  
- **NumPy / Pandas** – data manipulation  
- **Frontend** – React for UI components  

---

Installation

1. Clone the repository:

```bash
git clone https://github.com/yourusername/Real-time-sign-language-communication-system.git
cd fyp_webapp
